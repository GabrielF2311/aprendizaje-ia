# ğŸ² Probabilidad y EstadÃ­stica - Semanas 7-10

## ğŸ¯ Objetivos del MÃ³dulo

- Dominar conceptos probabilÃ­sticos fundamentales
- Entender distribuciones de probabilidad
- Aplicar estadÃ­stica descriptiva e inferencial
- Usar herramientas estadÃ­sticas para ML

**DuraciÃ³n**: 4 semanas (Probabilidad: 2 semanas, EstadÃ­stica: 2 semanas)

---

## ğŸ“‚ Estructura

```
Probabilidad_Estadistica/
â”œâ”€â”€ README.md (este archivo)
â”œâ”€â”€ probabilidad/              # Semanas 7-8
â”‚   â”œâ”€â”€ fundamentos/
â”‚   â”œâ”€â”€ distribuciones/
â”‚   â””â”€â”€ proyecto_monte_carlo/
â””â”€â”€ estadistica/               # Semanas 9-10
    â”œâ”€â”€ descriptiva/
    â”œâ”€â”€ inferencial/
    â””â”€â”€ proyecto_analisis/
```

---

## PARTE 1: PROBABILIDAD (Semanas 7-8)

### ğŸ² Semana 7: Fundamentos de Probabilidad

#### DÃ­a 1: Probabilidad BÃ¡sica
- Experimentos aleatorios
- Espacio muestral
- Eventos y probabilidad
- Axiomas de probabilidad
- Probabilidad condicional

#### DÃ­a 2: Teorema de Bayes
- Probabilidad conjunta
- Probabilidad condicional
- Teorema de Bayes
- Aplicaciones: clasificadores Bayesianos

#### DÃ­a 3: Variables Aleatorias
- Discretas vs continuas
- FunciÃ³n de masa/densidad de probabilidad
- FunciÃ³n de distribuciÃ³n acumulativa
- Esperanza (valor esperado)
- Varianza y desviaciÃ³n estÃ¡ndar

### ğŸ² Semana 8: Distribuciones de Probabilidad

#### DÃ­a 4: Distribuciones Discretas
- Bernoulli (ensayo Ãºnico)
- Binomial (n ensayos)
- Poisson (eventos en tiempo)
- GeomÃ©trica

#### DÃ­a 5-6: Distribuciones Continuas
- Uniforme
- Normal (Gaussiana) â­
- Exponencial
- Beta, Gamma

#### DÃ­a 7: Proyecto - Simulaciones Monte Carlo
- Simular procesos aleatorios
- Estimar Ï€ con Monte Carlo
- Aplicaciones en IA

---

## PARTE 2: ESTADÃSTICA (Semanas 9-10)

### ğŸ“Š Semana 9: EstadÃ­stica Descriptiva e Inferencial

#### DÃ­a 1: EstadÃ­stica Descriptiva
- Medidas de tendencia central (media, mediana, moda)
- Medidas de dispersiÃ³n (varianza, std, rango)
- Percentiles y quartiles
- VisualizaciÃ³n de datos

#### DÃ­a 2: Muestreo
- PoblaciÃ³n vs muestra
- Tipos de muestreo
- Error estÃ¡ndar
- Teorema del lÃ­mite central

#### DÃ­a 3: Intervalos de Confianza
- EstimaciÃ³n puntual vs intervalo
- Intervalos de confianza
- Nivel de confianza (95%, 99%)

### ğŸ“Š Semana 10: CorrelaciÃ³n y AnÃ¡lisis

#### DÃ­a 4: Pruebas de HipÃ³tesis
- HipÃ³tesis nula vs alternativa
- p-value
- Errores tipo I y II
- t-test, z-test

#### DÃ­a 5: CorrelaciÃ³n y Covarianza
- Covarianza
- CorrelaciÃ³n de Pearson
- CorrelaciÃ³n de Spearman
- InterpretaciÃ³n

#### DÃ­a 6-7: Proyecto - AnÃ¡lisis EstadÃ­stico Completo
- EDA estadÃ­stico de dataset
- Pruebas de hipÃ³tesis
- Correlaciones
- Conclusiones

---

## ğŸ“š Conceptos Clave - PROBABILIDAD

### Probabilidad BÃ¡sica

$$P(A) = \frac{\text{Casos favorables}}{\text{Casos totales}}$$

**Propiedades**:
- $0 \leq P(A) \leq 1$
- $P(\Omega) = 1$ (espacio muestral)
- $P(A \cup B) = P(A) + P(B) - P(A \cap B)$

### Probabilidad Condicional

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

**Lectura**: "Probabilidad de A dado que B ocurriÃ³"

### Teorema de Bayes

$$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$$

**AplicaciÃ³n en IA**: Clasificadores Naive Bayes

```python
# Ejemplo: Spam detection
# P(spam | contiene "gratis") = ?

P_spam = 0.3  # Prior: 30% de emails son spam
P_gratis_dado_spam = 0.8  # Likelihood
P_gratis = 0.35  # Evidence

P_spam_dado_gratis = (P_gratis_dado_spam * P_spam) / P_gratis
print(f"P(spam | 'gratis') = {P_spam_dado_gratis:.2%}")
```

### Esperanza y Varianza

**Esperanza** (valor esperado):
$$E[X] = \sum x_i \cdot P(x_i)$$ (discreta)
$$E[X] = \int x \cdot f(x) dx$$ (continua)

**Varianza**:
$$Var(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$

### DistribuciÃ³n Normal

La mÃ¡s importante en estadÃ­stica:

$$f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$

Propiedades:
- SimÃ©trica alrededor de $\mu$ (media)
- 68% dentro de 1 std
- 95% dentro de 2 std
- 99.7% dentro de 3 std

```python
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# Crear distribuciÃ³n normal
mu, sigma = 0, 1
x = np.linspace(-4, 4, 1000)
y = stats.norm.pdf(x, mu, sigma)

plt.plot(x, y)
plt.title('DistribuciÃ³n Normal EstÃ¡ndar')
plt.show()
```

---

## ğŸ“š Conceptos Clave - ESTADÃSTICA

### Medidas de Tendencia Central

```python
import numpy as np

data = [1, 2, 3, 4, 5, 5, 6, 7, 8, 9]

media = np.mean(data)        # Promedio
mediana = np.median(data)    # Valor central
moda = stats.mode(data)      # MÃ¡s frecuente
```

### Medidas de DispersiÃ³n

```python
varianza = np.var(data)      # Promedio de desviacionesÂ²
std = np.std(data)           # RaÃ­z de varianza
rango = np.max(data) - np.min(data)
```

### Teorema del LÃ­mite Central

**Idea clave**: La media de muestras grandes tiende a distribuirse normalmente, sin importar la distribuciÃ³n original.

```python
# DemostraciÃ³n
samples = [np.mean(np.random.exponential(size=50)) for _ in range(1000)]
plt.hist(samples, bins=30)
plt.title('DistribuciÃ³n de medias muestrales - Se ve Normal!')
plt.show()
```

### Intervalos de Confianza

**Intervalo del 95%**:
$$[\bar{x} - 1.96\frac{s}{\sqrt{n}}, \bar{x} + 1.96\frac{s}{\sqrt{n}}]$$

```python
from scipy import stats

# Calcular IC 95%
confidence = 0.95
data = np.random.normal(100, 15, 50)
ci = stats.t.interval(confidence, len(data)-1, 
                       loc=np.mean(data), 
                       scale=stats.sem(data))
print(f"IC 95%: {ci}")
```

### Pruebas de HipÃ³tesis

**Proceso**:
1. Formular $H_0$ (hipÃ³tesis nula) y $H_1$ (alternativa)
2. Elegir nivel de significancia ($\alpha = 0.05$)
3. Calcular estadÃ­stico de prueba
4. Calcular p-value
5. DecisiÃ³n: Si p-value < $\alpha$, rechazar $H_0$

```python
# t-test: Â¿Las medias son diferentes?
group_a = [23, 25, 27, 24, 26]
group_b = [30, 32, 31, 33, 29]

t_stat, p_value = stats.ttest_ind(group_a, group_b)
print(f"p-value: {p_value}")

if p_value < 0.05:
    print("Rechazamos H0: Las medias SON diferentes")
else:
    print("No rechazamos H0: No hay evidencia de diferencia")
```

### CorrelaciÃ³n

**CorrelaciÃ³n de Pearson** (lineal):
$$r = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\sum(x_i - \bar{x})^2 \sum(y_i - \bar{y})^2}}$$

Rango: $[-1, 1]$
- $r = 1$: CorrelaciÃ³n positiva perfecta
- $r = 0$: Sin correlaciÃ³n
- $r = -1$: CorrelaciÃ³n negativa perfecta

```python
# Calcular correlaciÃ³n
x = [1, 2, 3, 4, 5]
y = [2, 4, 5, 4, 5]

correlation = np.corrcoef(x, y)[0, 1]
print(f"CorrelaciÃ³n: {correlation:.3f}")

# Visualizar
plt.scatter(x, y)
plt.title(f'CorrelaciÃ³n: {correlation:.3f}')
plt.show()
```

---

## ğŸ’» Proyectos

### Proyecto 1: Simulador Monte Carlo

**Objetivo**: Usar simulaciones para resolver problemas

**Tareas**:
1. Estimar Ï€ lanzando puntos aleatorios
2. Simular el problema de Monty Hall
3. Calcular probabilidad de ganar la loterÃ­a
4. Simular random walks

### Proyecto 2: AnÃ¡lisis EstadÃ­stico Completo

**Objetivo**: AnÃ¡lisis exhaustivo de un dataset

**Tareas**:
1. Cargar dataset (Kaggle, UCI ML Repository)
2. EstadÃ­stica descriptiva completa
3. Visualizaciones (histogramas, boxplots, scatter)
4. Pruebas de normalidad
5. Correlaciones entre variables
6. Pruebas de hipÃ³tesis
7. Conclusiones y reportes

---

## âœ… Checklist Completo

### Probabilidad
- [ ] Entiendo probabilidad bÃ¡sica y condicional
- [ ] Puedo aplicar teorema de Bayes
- [ ] Conozco variables aleatorias y esperanza
- [ ] Domino distribuciones (Binomial, Normal, Poisson)
- [ ] ImplementÃ© simulaciones Monte Carlo

### EstadÃ­stica
- [ ] Calculo medidas descriptivas
- [ ] Entiendo muestreo y CLT
- [ ] Construyo intervalos de confianza
- [ ] Realizo pruebas de hipÃ³tesis
- [ ] Interpreto correlaciones
- [ ] CompletÃ© anÃ¡lisis estadÃ­stico de dataset

---

## ğŸ”— ConexiÃ³n con Machine Learning

### Probabilidad en ML

**ClasificaciÃ³n ProbabilÃ­stica**:
```python
# Logistic Regression predice P(y=1|x)
# Naive Bayes usa Teorema de Bayes
# GANs modelan distribuciones de datos
```

**RegularizaciÃ³n Bayesiana**:
```python
# Ridge Regression = Gaussian prior
# Lasso = Laplacian prior
```

### EstadÃ­stica en ML

**ValidaciÃ³n de Modelos**:
- t-test para comparar modelos
- Intervalos de confianza para mÃ©tricas
- CorrelaciÃ³n para feature selection

**A/B Testing**:
- Pruebas de hipÃ³tesis para experimentos
- Determinar si un cambio tiene efecto

---

## ğŸ“š Recursos

### Libros
- *Introduction to Probability* - Blitzstein & Hwang
- *Statistics* - Freedman, Pisani, Purves
- *Think Stats* - Allen Downey (Python)

### Videos
- **StatQuest**: Todos los videos de estadÃ­stica
- **Khan Academy**: Probability and Statistics
- **3Blue1Brown**: Bayesian Theorem

### PrÃ¡cticas
- [Seeing Theory](https://seeing-theory.brown.edu/) - Visualizaciones interactivas
- [Probability & Statistics Cookbook](http://statistics.zone/)

---

**Â¡La probabilidad y estadÃ­stica son fundamentales para entender ML!** ğŸ²ğŸ“Š

**Siguiente MÃ³dulo**: Python para IA
