# üìä C√°lculo y Optimizaci√≥n - Semanas 5 y 6

## üéØ Objetivos

- Entender derivadas y su interpretaci√≥n
- Calcular derivadas parciales
- Dominar la regla de la cadena
- Implementar descenso por gradiente
- Optimizar funciones desde cero

---

## üìÖ Plan de las 2 Semanas

### **Semana 5: Derivadas y Gradientes**

#### D√≠a 1: Derivadas B√°sicas
- Definici√≥n de derivada
- Interpretaci√≥n geom√©trica (pendiente)
- Reglas de derivaci√≥n
- Derivadas comunes

#### D√≠a 2: Regla de la Cadena
- Composici√≥n de funciones
- Chain rule
- Aplicaci√≥n: backpropagation

#### D√≠a 3: Derivadas Parciales
- Funciones multivariables
- Derivadas parciales
- Notaci√≥n $\frac{\partial f}{\partial x}$

#### D√≠a 4: Gradientes
- Vector gradiente
- Direcci√≥n de m√°ximo crecimiento
- Visualizaci√≥n de gradientes

### **Semana 6: Optimizaci√≥n**

#### D√≠a 5: Descenso por Gradiente
- Idea fundamental
- Algoritmo de gradient descent
- Learning rate
- Convergencia

#### D√≠a 6-7: PROYECTO - Optimizador
- Implementar gradient descent desde cero
- Aplicar a regresi√≥n lineal
- Visualizar el proceso
- Comparar learning rates

---

## üìö Teor√≠a Fundamental

### Derivada

La **derivada** mide la tasa de cambio instant√°nea:

$$f'(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}$$

**Interpretaci√≥n geom√©trica**: Pendiente de la recta tangente

### Reglas de Derivaci√≥n

| Funci√≥n | Derivada |
|---------|----------|
| $c$ (constante) | $0$ |
| $x^n$ | $nx^{n-1}$ |
| $e^x$ | $e^x$ |
| $\ln(x)$ | $\frac{1}{x}$ |
| $\sin(x)$ | $\cos(x)$ |
| $\cos(x)$ | $-\sin(x)$ |

**Regla de la suma**: $(f + g)' = f' + g'$
**Regla del producto**: $(fg)' = f'g + fg'$
**Regla de la cadena**: $(f(g(x)))' = f'(g(x)) \cdot g'(x)$

### Derivadas Parciales

Para funciones de varias variables $f(x, y)$:

$$\frac{\partial f}{\partial x} = \text{derivada respecto a } x \text{ (manteniendo } y \text{ constante)}$$

### Gradiente

El **gradiente** es un vector de todas las derivadas parciales:

$$\nabla f = \left[\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, ..., \frac{\partial f}{\partial x_n}\right]$$

**Propiedad clave**: El gradiente apunta en la direcci√≥n de m√°ximo crecimiento.

### Descenso por Gradiente

Algoritmo para minimizar una funci√≥n:

$$x_{new} = x_{old} - \alpha \nabla f(x_{old})$$

Donde $\alpha$ es el **learning rate** (tasa de aprendizaje).

---

## üíª Implementaciones

### Derivada Num√©rica

```python
def derivative(f, x, h=1e-5):
    """Aproxima la derivada de f en x"""
    return (f(x + h) - f(x)) / h

# Ejemplo
f = lambda x: x**2
print(f"f'(3) ‚âà {derivative(f, 3)}")  # Deber√≠a ser ~6
```

### Gradiente Num√©rico

```python
import numpy as np

def gradient(f, x, h=1e-5):
    """
    Calcula gradiente num√©rico de f en punto x.
    
    Args:
        f: funci√≥n escalar que recibe vector
        x: punto donde evaluar (numpy array)
        h: paso para aproximaci√≥n
        
    Returns:
        Vector gradiente
    """
    grad = np.zeros_like(x)
    
    for i in range(len(x)):
        x_plus = x.copy()
        x_plus[i] += h
        
        x_minus = x.copy()
        x_minus[i] -= h
        
        grad[i] = (f(x_plus) - f(x_minus)) / (2 * h)
    
    return grad
```

### Descenso por Gradiente

```python
def gradient_descent(f, grad_f, x_init, learning_rate=0.1, iterations=100):
    """
    Minimiza funci√≥n f usando gradient descent.
    
    Args:
        f: funci√≥n a minimizar
        grad_f: funci√≥n que calcula el gradiente
        x_init: punto inicial
        learning_rate: tasa de aprendizaje
        iterations: n√∫mero de iteraciones
        
    Returns:
        x_min: punto m√≠nimo encontrado
        history: historia de valores
    """
    x = x_init.copy()
    history = [x.copy()]
    
    for i in range(iterations):
        # Calcular gradiente
        grad = grad_f(x)
        
        # Actualizar par√°metros
        x = x - learning_rate * grad
        
        history.append(x.copy())
        
        # Opcional: imprimir progreso
        if i % 10 == 0:
            print(f"Iter {i}: f(x) = {f(x):.4f}")
    
    return x, np.array(history)
```

---

## üéØ Ejercicios Pr√°cticos

### Ejercicio 1: Derivadas a Mano

Calcula las derivadas de:
1. $f(x) = 3x^2 + 2x + 1$
2. $g(x) = e^{2x}$
3. $h(x) = \ln(x^2 + 1)$
4. $k(x) = \sin(x^2)$ (usa regla de la cadena)

### Ejercicio 2: Implementa Derivadas Simb√≥licas

```python
class Expr:
    """Clase base para expresiones"""
    pass

class Var(Expr):
    """Variable x"""
    def derivative(self):
        return Const(1)

class Const(Expr):
    """Constante"""
    def __init__(self, value):
        self.value = value
    
    def derivative(self):
        return Const(0)

# TODO: Implementa Sum, Product, Power
# TODO: Implementa m√©todo derivative() para cada uno
```

### Ejercicio 3: Visualiza Descenso por Gradiente

```python
import matplotlib.pyplot as plt

def visualize_gradient_descent(f, grad_f, x_init, lr=0.1):
    """
    Visualiza el proceso de gradient descent.
    """
    # Ejecutar gradient descent
    x_min, history = gradient_descent(f, grad_f, x_init, lr, 50)
    
    # Crear gr√°fico
    x = np.linspace(-5, 5, 100)
    y = [f(np.array([xi])) for xi in x]
    
    plt.plot(x, y, 'b-', label='f(x)')
    plt.plot(history[:, 0], [f(h) for h in history], 
             'ro-', label='GD path', markersize=4)
    plt.xlabel('x')
    plt.ylabel('f(x)')
    plt.title(f'Gradient Descent (lr={lr})')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

# Prueba con f(x) = x^2
f = lambda x: x[0]**2
grad_f = lambda x: np.array([2*x[0]])
visualize_gradient_descent(f, grad_f, np.array([4.0]), lr=0.1)
```

---

## üèóÔ∏è PROYECTO: Regresi√≥n Lineal con Gradient Descent

### Objetivo
Implementar regresi√≥n lineal usando descenso por gradiente desde cero.

### Especificaciones

```python
class LinearRegressionGD:
    """Regresi√≥n lineal con gradient descent"""
    
    def __init__(self, learning_rate=0.01, iterations=1000):
        self.lr = learning_rate
        self.iterations = iterations
        self.weights = None
        self.bias = None
        self.history = []
    
    def fit(self, X, y):
        """
        Entrena el modelo.
        
        Args:
            X: Features (n_samples, n_features)
            y: Target (n_samples,)
        """
        n_samples, n_features = X.shape
        
        # Inicializar par√°metros
        self.weights = np.zeros(n_features)
        self.bias = 0
        
        # Gradient descent
        for i in range(self.iterations):
            # Predicci√≥n
            y_pred = np.dot(X, self.weights) + self.bias
            
            # Calcular loss (MSE)
            loss = np.mean((y_pred - y) ** 2)
            self.history.append(loss)
            
            # Calcular gradientes
            dw = (1/n_samples) * np.dot(X.T, (y_pred - y))
            db = (1/n_samples) * np.sum(y_pred - y)
            
            # Actualizar par√°metros
            self.weights -= self.lr * dw
            self.bias -= self.lr * db
    
    def predict(self, X):
        """Hace predicciones"""
        return np.dot(X, self.weights) + self.bias
    
    def plot_loss(self):
        """Visualiza la convergencia"""
        plt.plot(self.history)
        plt.xlabel('Iteration')
        plt.ylabel('Loss (MSE)')
        plt.title('Training Loss Over Time')
        plt.grid(True, alpha=0.3)
        plt.show()
```

### Tareas del Proyecto

1. **Implementa la clase completa**
2. **Genera datos sint√©ticos**:
   ```python
   X = 2 * np.random.rand(100, 1)
   y = 4 + 3 * X + np.random.randn(100, 1)
   ```
3. **Entrena el modelo** con diferentes learning rates
4. **Visualiza**:
   - Datos y l√≠nea de regresi√≥n
   - Convergencia del loss
   - Comparaci√≥n de learning rates
5. **Experimenta**:
   - ¬øQu√© pasa con lr muy grande?
   - ¬øQu√© pasa con lr muy peque√±o?
   - ¬øCu√°ntas iteraciones necesitas?

---

## ‚úÖ Checklist

### Teor√≠a
- [ ] Entiendo qu√© es una derivada
- [ ] Puedo calcular derivadas a mano
- [ ] Entiendo la regla de la cadena
- [ ] S√© qu√© son derivadas parciales
- [ ] Entiendo el gradiente y su interpretaci√≥n

### Implementaci√≥n
- [ ] Calcul√© derivadas num√©ricas
- [ ] Calcul√© gradientes num√©ricos
- [ ] Implement√© gradient descent desde cero
- [ ] Visualic√© el proceso de optimizaci√≥n

### Proyecto
- [ ] Regresi√≥n lineal con GD funciona
- [ ] Prob√© diferentes learning rates
- [ ] Visualic√© convergencia
- [ ] Entiendo cu√°ndo converge/diverge

---

## üîó Conexi√≥n con Deep Learning

### Backpropagation = Regla de la Cadena

```python
# Red neuronal simple: y = œÉ(Wx + b)
# Para entrenar, necesitamos ‚àÇL/‚àÇW

# Regla de la cadena:
# ‚àÇL/‚àÇW = ‚àÇL/‚àÇy ¬∑ ‚àÇy/‚àÇz ¬∑ ‚àÇz/‚àÇW
# donde z = Wx + b, y = œÉ(z), L = loss

# Esto es exactamente backpropagation!
```

### Optimizadores Modernos

El gradient descent b√°sico evoluciona a:
- **SGD con Momentum**: A√±ade inercia
- **Adam**: Learning rate adaptativo
- **RMSprop**: Normaliza gradientes

Pero todos se basan en: **$x_{new} = x - \alpha \nabla f(x)$**

---

## üìö Recursos

### Videos
- **3Blue1Brown**: "Essence of Calculus" (serie completa)
- **Khan Academy**: Differential Calculus

### Interactivos
- [Desmos Graphing Calculator](https://www.desmos.com/calculator)
- [Seeing Theory - Optimization](https://seeing-theory.brown.edu/)

---

**¬°El c√°lculo es el coraz√≥n del Deep Learning!** üßÆ

**Siguiente**: Probabilidad y Estad√≠stica
